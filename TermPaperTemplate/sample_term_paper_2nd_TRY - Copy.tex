%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf, nonacm, natbib, screen, balance=False]{acmart}

% Documentation for packages
% - ACM Article Template
%    https://www.acm.org/publications/proceedings-template
% - Pseudocode typesetting CLRS-style:
%    https://www.cs.dartmouth.edu/~thc/clrscode/clrscode3e.pdf
% - Python code typesetting
%    http://ctan.uib.no/macros/latex/contrib/listings/listings.pdf
% - AMS Math
%    http://ctan.uib.no/macros/latex/required/amsmath/amsldoc.pdf
% - Graphics
%    http://ctan.uib.no/macros/latex/required/graphics/grfguide.pdf

\usepackage{clrscode3e}  
\usepackage{listings}
\lstset{language=Python, basicstyle=\ttfamily}

%adding package for the font error
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% based on https://tex.stackexchange.com/questions/279240/float-for-lstlisting
\usepackage{float}
\floatstyle{ruled}
\newfloat{listing}{tbph}{lop}
\floatname{listing}{Listing}
\def\lstfloatautorefname{Listing} % needed for hyperref/auroref

\citestyle{acmauthoryear}

%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Benchmarking sorting algorithms in Python}
\subtitle{INF221 Term Paper, NMBU, Autumn 2019}

\author{Bishnu Poudel}
\email{bishnu.poudel@nmbu.no}
\affiliation{MS in Data Science, NMBU} 

\author{Mohamed Radwan}
\email{mohamed.radwan@nmbu.no}
\affiliation{MS in Data Science, NMBU} 

%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
In this paper, we generate the runtimes for three pure sorting algorithms that follow the divide-and-conquer approach. In addition, we benchmark the inbuilt numpy sort function- np.sort() and also the python sort function - sorted(). 
Then we compare these real-life runtimes with the theoritical runtimes that we have learnt as a part of the Algorithms 
and data structure course at NMBU. We also analyse and plot the distributions of runtimes we foundData is collected for list sizes  from 10 to 10 million in order to study the asymtotic behavior of these algorithms.
The work has been done using python and its libraries.
\end{abstract}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}\label{sec:intro}


Sorting and searching are basic and routine operations for computers of any type. Much research has already been done in the subject, and computers today use the most robust algorithms possible that meet their specific requirement/application. Many applications use a blend of 2 or more algorithms depending on the nature input data or the application.  However, it would be interesting to see how the  sorting algorithms behave stand-alone  in real life.

In the following section, we are benchmarking sorting algorithms in python based on their runtimes. This paper is also the final 
term-paper for the 'Computer Science for Data Scientists'  course at NMBU. Here, we get to compare the theoritical runtimes of sorting algorithms  to their real-life runtimes.

The main questions we are trying to address are: Do the algorithms show their theoritical average case behavior in real situations? 
Which of the stand alone sort is more efficient? Do these standalone sorts have a chance against the built-in sorts of numpy and python?
How are the runtimes of each run distributed, is there any statistical significance in the distribution?

In the Theory section, we describe the psuedo-code of the algorithms together with their theoritical runtimes. We discuss the best, average and the worst cases.  In the Methods section, we describe the python implementation of the algorithms, together with the python functions  we 
wrote to extract the runtime information. We also discuss the type and amount of data we collected. Results section has facts and figures from 
our analysis. In the Discussion section, we summarize our findings and compare them to the theoritical expectations. We also compare the 
standalone algorithms with the pre-implemented algorithms in numpy and python. Acknowledgements and References conclude the paper.


\section{Theory}\label{sec:theory}


\subsection{Heap Sort}\label{sec:heap sort}

\begin{listing}
  % Pseudocode caption above the code.
  \caption{Heap sort algorithm from \citet[Ch.~6.4]{CLRS_2009}.}
  \label{lst:heap_algo}

\begin{verbatim}
HEAP-SORT(A)
    BUILD-MAX_HEAP(A)
    for i = A.length downto 2
        swap A[1] and A[i]
        A.heap_size = A.heap_size - 1
        MAX-HEAPIFY(A, 1)
\end{verbatim}
\end{listing}

Heap sort uses the max-heap (or min heap property) to sort elements in an array. Due to this, heap sort is not stable. Therefore, the keys having exact value might be interchanged. Theoritically, all 3 cases of heap sort (worst, best and average)
are of the order $n*log(n)$. We wrote a python implementation of psuedo code above to sort the array in place. It will be interesting to see which of the three sets of data ( random, ordered, reversely ordered) data performs the best on heap sort. 

\subsection{Merge Sort}\label{sec:merge sort}

\begin{listing}
  % Pseudocode caption above the code.
  \caption{Merge sort algorithm from \citet[Ch.~2.3.1]{CLRS_2009}.}
  \label{lst:merge_algo}

\begin{verbatim}
MERGE-SORT(A,p,q)
    if p < r
    q = (p + r)/2
    MERGE-SORT(A, p, q)
    MERGE-SORT(A, q + 1, r)
    MERGE(A, p, q, r)
\end{verbatim}
\end{listing}

Here the MERGE function simply merges two lists, both of which are already sorted. Merge sort probably got its name from this sub-process of the algorithm.Merge sort is the most intuitive divide and conquer approach to sorting, as it is dividing the list 
recursively in two equal halves ( if the list has odd number of elements, one half has 1 more element than the other).

Merge sort has the runtime of the order of $n*log(n)$ in all of its best, average and worst cases. It will be interesting to see 
if the already sorted data is the best case for a merge sort.

\subsection{Quick Sort}\label{sec:quick sort}

\begin{listing}
  % Pseudocode caption above the code.
  \caption{Quick sort algorithm from \citet[Ch.~2.3.1]{CLRS_2009}.}
  \label{lst:quick_algo}

\begin{verbatim}
QUICKSORT(A, p, r)
    if p < r
        q = PARTITION(A, p, r)
        QUICKSORT(A, p, q-1)
        QUICKSORT(A, q+1, r)


PARTITION(A, p, r)
    x = A[r]
    i = p - 1
    for j = p to r - 1
        if A[j] <= x
            i = i + 1
            swap A[i] and A[j]
    swap A[i + 1] and A[r]
    return i + 1
\end{verbatim}
\end{listing}

In case of quicksort, most of the work is done by the PARTITION function. It does the inplace swapping of the list elements. It also 
returns the position of the pivot element to the QUICKSORT function.

 Quicksort has a average and best case runtime of the order of $n*log(n)$, (the best case has a smaller constant of course).
 However, in the case where each subsequent partition has only one less element than the last partition, it runs
into its worst case and has a theoritical runtime of $n^2$. It will be interesting to see if we indeed run into this scenario.

\subsection{Numpy's numpy.sort()}\label{sec:numpy sort}
The numpy sort function uses quicksort and a combination of few other sorts depending on the input data. Yet to 
put reference article or link here...

\subsection{Python's default sorted()}\label{sec:sorted sort}
Python uses a now popularly used sort algorithm in many programming languages, called timsort which is named after its
inventor. Yet to put reference article or link here...

\section{Methods}\label{sec:methods}

\subsection{Python implementation of algorithms}\label{sec:python implementation}

We wrote the python implementations for heap sort, merge sort and quick sort following the psuedo code from CLRS. We wrote
the code in a way that the only input we need to provide is the input array. The functions will calculate the length of the array 
or subarrayif their algorithm needs the length. Merge sort and quick sort call themselves recursively with 3 parameters, while heap
sort does it with a single parameter. All the python codes, data generated and figures can be found at https://github.com/vsnupoudel/termpaper01.
It was interesting to see that we could implement quicksort in a few lines. Below we can see the partition function used for quicksort.

\begin{listing}
  % Pseudocode caption above the code.
  \caption{Quick sort PARTITION FUNCTION}
  \label{lst:quick_partition}

\begin{verbatim}
def quick_comparison_and_swap (Inputlist, start, end): 
    pivot_last = Inputlist[end]
    index_less_than = start -1
    
    for comparison_index in range(start,end):
        if Inputlist[c_index]<= pivot_last:
            l_index += 1
            Inputlist[l_index], Inputlist[c_index]
            = Inputlist[c_index], Inputlist[l_index]  
            
    Inputlist[end] , Inputlist[l_index+1] 
    =   Inputlist[l_index+1], Inputlist[end]  

    return index_less_than+1  
\end{verbatim}
\end{listing}

\subsection{Timing function}\label{sec:timing function}

Secondly, to benchmark the 3 algorithms we  implemented along with numpy.sort() and sorted(), we use the timeit library. The skeleton of the 
function was provided by professor H.E. Plesser, which is built on. Since the process can slow down due to other processes in the computer, w
e repeated each of the timeit experiments 7 times and took the fastest time among the 7. We export the runtimes of these algorithms for 
list of size ranging from 10 to 10 million. We use the same seed all the time, so that the data we use is exactly same at all times.

\begin{listing}
  % Pseudocode caption above the code.
  \caption{Time it function used with parameters}
  \label{lst:time_it function}

\begin{verbatim}
import numpy as np
import timeit
import copy

def timing_function(number_of_data_points, sort_type
,randomization_type, seed_number=12235):
    np.random.seed (seed_number)
    test_data = np.random.random(number_of_data_points ,)
    test_data = list(test_data)

    if randomization_type=='reverse':
        test_data= sorted(test_data, reverse =True)
    elif randomization_type=='sorted':
        test_data= sorted(test_data)

    clock = timeit.Timer ( stmt ='sort_func ( copy ( data) ) ', 
                           globals ={ 'sort_func': sort_type ,
                            'data': test_data ,
                            'copy': copy.copy })
    n_ar , t_ar = clock.autorange ()
    t = clock.repeat ( repeat =7, number = n_ar )
    return t
\end{verbatim}
\end{listing}

\subsection{Analysis, tables and plots}\label{sec:analysis}
After that, we compare the runtimes of 5 algorithms for all data sizes in a number of line graphs. Similary, we plot a scatter plot of the 7 runtimes 
we got for each of the algorithms and see if they show any statistical significance. We also compare the runtime for reverse sorted and already sorted
data and see if it drastically different than the random data for any of the algorithm.

\subsection{Hardwares and softwares}\label{sec:hardwares and softwares}
The runtimes were obtained from a machine with the follwing configuration. 

Also, the following version of python and its libraries were used.
\begin{itemize}
\item Processor:    AMD A4-3330MX APU  2.30 GHz
\item Caches:        L1D-64 KB*2 , L1I-64KB*2, L2 -512KB*2
\item Memory :      DDR3 4 GB, 800 MHz
\item OS :              Microsoft Windows 7 Professional
\end{itemize}
Details with screenshots are at https://github.com/vsnupoudel/termpaper01.

Following are the versions of packages used in Python 3.7.4:
\begin{itemize}
\item Pandas:    '0.25.1'
\item Pandasql:    '0.7.3'
\item Numpy :      '1.16.5'
\item matplotlib :          '3.1.1'
\item nbimporter :          '0.3.1'
\item timeit :         
\item pickle :       
\item copy :        
\end{itemize}


\section{Results}\label{sec:results}
We can see that numpy sort is the most efficient for large list size...
Then comes Python sorted...
....
.....


\section{Discussion}\label{sec:discussion}
Since numpy uses.... and python uses....
Quick sort ran into maximum recursion....
....




\section{Acknowledgements}\label{sec:acknowledgements}
We would like to thank Professor H.E Plesser and our TA Krista Gilman for their guidance and for answering our
questions related to the paper.

\section{References}\label{sec:references}
.......
..........
...............

%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample_bib}

\end{document}
